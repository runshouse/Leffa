{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/yachty66/Leffa.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Leffa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from huggingface_hub import snapshot_download\n",
    "from leffa.transform import LeffaTransform\n",
    "from leffa.model import LeffaModel\n",
    "from leffa.inference import LeffaInference\n",
    "from leffa_utils.garment_agnostic_mask_predictor import AutoMasker\n",
    "from leffa_utils.densepose_predictor import DensePosePredictor\n",
    "from leffa_utils.utils import resize_and_center, get_agnostic_mask\n",
    "from preprocess.humanparsing.run_parsing import Parsing\n",
    "from preprocess.openpose.run_openpose import OpenPose\n",
    "\n",
    "class LeffaPredictor:\n",
    "    def __init__(self, download_weights=True):\n",
    "        # Download checkpoints if needed\n",
    "        if download_weights:\n",
    "            snapshot_download(\n",
    "                repo_id=\"franciszzj/Leffa\", \n",
    "                local_dir=\"./ckpts\",\n",
    "                allow_patterns=[\n",
    "                    \"densepose/*\",\n",
    "                    \"schp/*\",\n",
    "                    \"humanparsing/*\",\n",
    "                    \"openpose/*\",\n",
    "                    \"stable-diffusion-inpainting/*\",\n",
    "                    \"virtual_tryon.pth\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        # Initialize models\n",
    "        self.mask_predictor = AutoMasker(\n",
    "            densepose_path=\"./ckpts/densepose\",\n",
    "            schp_path=\"./ckpts/schp\",\n",
    "        )\n",
    "\n",
    "        self.densepose_predictor = DensePosePredictor(\n",
    "            config_path=\"./ckpts/densepose/densepose_rcnn_R_50_FPN_s1x.yaml\",\n",
    "            weights_path=\"./ckpts/densepose/model_final_162be9.pkl\",\n",
    "        )\n",
    "\n",
    "        self.parsing = Parsing(\n",
    "            atr_path=\"./ckpts/humanparsing/parsing_atr.onnx\",\n",
    "            lip_path=\"./ckpts/humanparsing/parsing_lip.onnx\",\n",
    "        )\n",
    "\n",
    "        self.openpose = OpenPose(\n",
    "            body_model_path=\"./ckpts/openpose/body_pose_model.pth\",\n",
    "        )\n",
    "\n",
    "        # Initialize virtual try-on model\n",
    "        vt_model = LeffaModel(\n",
    "            pretrained_model_name_or_path=\"./ckpts/stable-diffusion-inpainting\",\n",
    "            pretrained_model=\"./ckpts/virtual_tryon.pth\",\n",
    "        )\n",
    "        self.vt_inference = LeffaInference(model=vt_model)\n",
    "        self.vt_model_type = \"viton_hd\"\n",
    "\n",
    "    def virtual_tryon(self, person_image_path, garment_image_path, garment_type=\"upper_body\", steps=50, scale=2.5, seed=42):\n",
    "        \"\"\"\n",
    "        Perform virtual try-on: Put garment on person\n",
    "        Args:\n",
    "            person_image_path (str): Path to person image\n",
    "            garment_image_path (str): Path to garment image\n",
    "            garment_type (str): Type of garment - \"upper_body\", \"lower_body\", or \"dresses\"\n",
    "            steps (int): Number of inference steps\n",
    "            scale (float): Guidance scale\n",
    "            seed (int): Random seed\n",
    "        Returns:\n",
    "            PIL.Image: Generated image with garment tried on\n",
    "        \"\"\"\n",
    "        # Load and preprocess images\n",
    "        src_image = Image.open(person_image_path)\n",
    "        ref_image = Image.open(garment_image_path)\n",
    "        src_image = resize_and_center(src_image, 768, 1024)\n",
    "        ref_image = resize_and_center(ref_image, 768, 1024)\n",
    "        src_image_array = np.array(src_image)\n",
    "\n",
    "        # Generate mask\n",
    "        src_image = src_image.convert(\"RGB\")\n",
    "        if self.vt_model_type == \"viton_hd\":\n",
    "            garment_type_hd = \"upper\" if garment_type in [\n",
    "                \"upper_body\", \"dresses\"] else \"lower\"\n",
    "            mask = self.mask_predictor(src_image, garment_type_hd)[\"mask\"]\n",
    "        elif self.vt_model_type == \"dress_code\":\n",
    "            keypoints = self.openpose(src_image.resize((384, 512)))\n",
    "            model_parse, _ = self.parsing(src_image.resize((384, 512)))\n",
    "            mask = get_agnostic_mask(model_parse, keypoints, garment_type)\n",
    "            mask = mask.resize((768, 1024))\n",
    "\n",
    "        # Generate DensePose\n",
    "        if self.vt_model_type == \"viton_hd\":\n",
    "            src_image_seg_array = self.densepose_predictor.predict_seg(src_image_array)\n",
    "            densepose = Image.fromarray(src_image_seg_array)\n",
    "        elif self.vt_model_type == \"dress_code\":\n",
    "            src_image_iuv_array = self.densepose_predictor.predict_iuv(src_image_array)\n",
    "            src_image_seg_array = src_image_iuv_array[:, :, 0:1]\n",
    "            src_image_seg_array = np.concatenate([src_image_seg_array] * 3, axis=-1)\n",
    "            densepose = Image.fromarray(src_image_seg_array)\n",
    "\n",
    "        # Prepare data for model\n",
    "        transform = LeffaTransform()\n",
    "        data = {\n",
    "            \"src_image\": [src_image],\n",
    "            \"ref_image\": [ref_image],\n",
    "            \"mask\": [mask],\n",
    "            \"densepose\": [densepose],\n",
    "        }\n",
    "        data = transform(data)\n",
    "\n",
    "        # Run inference\n",
    "        output = self.vt_inference(\n",
    "            data,\n",
    "            num_inference_steps=steps,\n",
    "            guidance_scale=scale,\n",
    "            seed=seed,\n",
    "        )\n",
    "        return Image.fromarray(output[\"generated_image\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! important before running this cell upload person_image_path and garment_image_path, in this case its person.jpg and jersey.jpg\n",
    "\n",
    "# Upload your images to Colab first\n",
    "from google.colab import files\n",
    "# uploaded = files.upload()  # This will prompt for person.jpg\n",
    "# uploaded = files.upload()  # This will prompt for jersey.jpg\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = LeffaPredictor()\n",
    "\n",
    "# Virtual try-on\n",
    "result = predictor.virtual_tryon(\n",
    "    person_image_path=\"person.jpg\",\n",
    "    garment_image_path=\"jersey.jpg\",\n",
    "    garment_type=\"upper_body\"  # or \"lower_body\" or \"dresses\"\n",
    ")\n",
    "\n",
    "# Display result\n",
    "display(result)\n",
    "\n",
    "# Save result\n",
    "result.save(\"result.png\")\n",
    "\n",
    "# Download the result\n",
    "files.download('result.png')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
